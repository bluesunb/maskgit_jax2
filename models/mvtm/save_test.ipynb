{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:48:43.489034Z",
     "start_time": "2024-03-21T03:48:42.905064Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax, jax.numpy as jp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "\n",
    "from models.vqgan import VQGAN"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from scripts.common import TrainState\n",
    "from config import VQConfig, AutoencoderConfig\n",
    "\n",
    "enc_config = AutoencoderConfig(out_channels=256,\n",
    "                               channel_multipliers=(1,2,4))\n",
    "dec_config = AutoencoderConfig(out_channels=3,\n",
    "                               channel_multipliers=(1,2,4))\n",
    "vq_config = VQConfig(codebook_size=512)\n",
    "\n",
    "gan = VQGAN(enc_config, dec_config, vq_config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:48:44.202094Z",
     "start_time": "2024-03-21T03:48:44.198568Z"
    }
   },
   "id": "551d269544da427e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "x = jax.random.normal(rng, (1, 256, 256, 3))\n",
    "variables = jax.jit(gan.init, static_argnames=['train'])({'params': rng, 'dropout': rng}, x, train=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:48:47.121011Z",
     "start_time": "2024-03-21T03:48:45.577715Z"
    }
   },
   "id": "b76e7a020334aef9",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "tx = optax.adam(1e-3)\n",
    "\n",
    "state = TrainState.create(gan, params=variables.pop('params'), tx=tx, extra_variables=variables)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:49:31.361535Z",
     "start_time": "2024-03-21T03:49:30.943731Z"
    }
   },
   "id": "45042dbab30aa844",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_step(state: TrainState, batch, rng):\n",
    "    def loss_fn(params):\n",
    "        x_recon, q_loss, result = state(batch, train=True, params=params, rngs={'dropout': rng})\n",
    "        loss = optax.l2_loss(batch, x_recon).mean()\n",
    "        result['recon_loss'] = loss\n",
    "        result['q_loss'] = q_loss\n",
    "        return loss, result\n",
    "    \n",
    "    state, info = state.apply_loss_fn(loss_fn, has_aux=True)\n",
    "    return state, info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:56:02.539918Z",
     "start_time": "2024-03-21T03:56:02.537354Z"
    }
   },
   "id": "1f2ed181925f3055",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 12:56:20.159418: W external/tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-03-21 12:56:22.295753: W external/tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 8.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'codebook_loss': Array(0.18131661, dtype=float32), 'commit_loss': Array(0.04532915, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.3099198, dtype=float32), 'indices': Array([[[347,  12, 234, ...,   6, 506, 421],\n",
      "        [455, 292, 426, ..., 149, 143, 418],\n",
      "        [ 78, 443,  46, ..., 347, 380,  14],\n",
      "        ...,\n",
      "        [ 65, 422, 221, ...,  47, 434,  31],\n",
      "        [422,  96, 443, ..., 205,  76, 166],\n",
      "        [407, 418, 344, ..., 439, 240, 498]]], dtype=int32), 'q_loss': Array(-0.08327404, dtype=float32), 'recon_loss': Array(0.7847867, dtype=float32)}\n",
      "{'codebook_loss': Array(0.6508399, dtype=float32), 'commit_loss': Array(0.16270998, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.0480988, dtype=float32), 'indices': Array([[[ 97,  48,  97, ..., 292, 149, 210],\n",
      "        [405, 405,  68, ...,  97, 201, 292],\n",
      "        [201, 201, 201, ..., 292, 201, 292],\n",
      "        ...,\n",
      "        [ 97, 144,  68, ..., 292, 292, 292],\n",
      "        [201, 201, 201, ..., 308,  97, 285],\n",
      "        [ 97, 308, 429, ..., 384, 292,  62]]], dtype=int32), 'q_loss': Array(0.7654511, dtype=float32), 'recon_loss': Array(1.6059955, dtype=float32)}\n",
      "{'codebook_loss': Array(1.3285844, dtype=float32), 'commit_loss': Array(0.3321461, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00895896, dtype=float32), 'indices': Array([[[ 72,  68, 149, ...,  68, 149,  68],\n",
      "        [442,  68,  68, ...,  68,  68,  68],\n",
      "        [ 68,  68,  68, ...,  68,  68,  68],\n",
      "        ...,\n",
      "        [ 97,  68,  68, ...,  68,  68,  68],\n",
      "        [442,  68,  68, ...,  68,  68, 467],\n",
      "        [ 68, 308, 467, ..., 467,  68, 467]]], dtype=int32), 'q_loss': Array(1.6517717, dtype=float32), 'recon_loss': Array(0.913558, dtype=float32)}\n",
      "{'codebook_loss': Array(1.9807578, dtype=float32), 'commit_loss': Array(0.49518946, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00668904, dtype=float32), 'indices': Array([[[ 72,  68,  68, ...,  68,  68,  68],\n",
      "        [442,  68,  68, ...,  68,  68,  68],\n",
      "        [ 68,  68,  68, ...,  68,  68,  68],\n",
      "        ...,\n",
      "        [ 68,  68,  68, ...,  68,  68, 467],\n",
      "        [442,  68,  68, ...,  68,  68, 467],\n",
      "        [442, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(2.4692583, dtype=float32), 'recon_loss': Array(0.6726176, dtype=float32)}\n",
      "{'codebook_loss': Array(2.6591291, dtype=float32), 'commit_loss': Array(0.6647823, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00507109, dtype=float32), 'indices': Array([[[442,  68,  68, ...,  68,  68,  68],\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        ...,\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        [442,  68,  68, ...,  68,  68, 467],\n",
      "        [ 68, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(3.3188403, dtype=float32), 'recon_loss': Array(0.64709485, dtype=float32)}\n",
      "{'codebook_loss': Array(3.337902, dtype=float32), 'commit_loss': Array(0.8344755, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00410684, dtype=float32), 'indices': Array([[[336,  68,  68, ...,  68,  68,  68],\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        ...,\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        [336, 336,  68, ...,  68,  68, 467],\n",
      "        [336, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(4.1682706, dtype=float32), 'recon_loss': Array(0.59696954, dtype=float32)}\n",
      "{'codebook_loss': Array(3.9755142, dtype=float32), 'commit_loss': Array(0.99387854, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.0034622, dtype=float32), 'indices': Array([[[336, 336, 336, ..., 336,  68,  68],\n",
      "        [336, 336, 336, ...,  68,  68, 467],\n",
      "        [336, 336, 336, ...,  68,  68, 467],\n",
      "        ...,\n",
      "        [336,  68,  68, ...,  68,  68, 467],\n",
      "        [336, 336, 336, ..., 467, 467, 467],\n",
      "        [336, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(4.9659305, dtype=float32), 'recon_loss': Array(0.5718267, dtype=float32)}\n",
      "{'codebook_loss': Array(4.5233, dtype=float32), 'commit_loss': Array(1.130825, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00326782, dtype=float32), 'indices': Array([[[336, 336, 336, ..., 336, 336, 467],\n",
      "        [336, 336, 336, ..., 336, 336, 467],\n",
      "        [336, 336, 336, ..., 336, 336, 467],\n",
      "        ...,\n",
      "        [336, 336, 336, ..., 336, 467, 467],\n",
      "        [336, 336, 336, ..., 467, 467, 467],\n",
      "        [336, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(5.6508574, dtype=float32), 'recon_loss': Array(0.5203018, dtype=float32)}\n",
      "{'codebook_loss': Array(5.0616894, dtype=float32), 'commit_loss': Array(1.2654223, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00278541, dtype=float32), 'indices': Array([[[336, 336, 336, ..., 336, 336, 467],\n",
      "        [336, 336, 336, ..., 336, 336, 467],\n",
      "        [336, 336, 336, ..., 336, 336, 467],\n",
      "        ...,\n",
      "        [336, 336, 336, ..., 336, 467, 467],\n",
      "        [336, 336, 336, ..., 467, 467, 467],\n",
      "        [336, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(6.3243265, dtype=float32), 'recon_loss': Array(0.5166924, dtype=float32)}\n",
      "{'codebook_loss': Array(5.405695, dtype=float32), 'commit_loss': Array(1.3514237, dtype=float32), 'encodings': Array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.],\n",
      "         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), 'entropy_loss': Array(-0.00260887, dtype=float32), 'indices': Array([[[336, 336, 336, ..., 336, 336, 467],\n",
      "        [336, 336, 336, ..., 336, 336, 467],\n",
      "        [336, 336, 336, ..., 336, 336, 467],\n",
      "        ...,\n",
      "        [336, 336, 336, ..., 336, 467, 467],\n",
      "        [336, 336, 336, ..., 467, 467, 467],\n",
      "        [336, 467, 467, ..., 467, 467, 467]]], dtype=int32), 'q_loss': Array(6.75451, dtype=float32), 'recon_loss': Array(0.5056982, dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "jit_train_step = jax.jit(train_step)\n",
    "\n",
    "for _ in range(10):\n",
    "    rng, subrng = jax.random.split(rng)\n",
    "    batch = jax.random.normal(rng, (1, 256, 256, 3))\n",
    "    state, info = jit_train_step(state, x, subrng)\n",
    "    print(info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:56:26.462030Z",
     "start_time": "2024-03-21T03:56:14.030032Z"
    }
   },
   "id": "b8ddec2c573fe068",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'codebook_loss': (),\n 'commit_loss': (),\n 'encodings': (1, 64, 64, 512),\n 'entropy_loss': (),\n 'indices': (1, 64, 64),\n 'q_loss': (),\n 'recon_loss': ()}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(jp.shape, info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:56:46.408038Z",
     "start_time": "2024-03-21T03:56:46.403438Z"
    }
   },
   "id": "13787ed69f082105",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bluesun/PycharmProjects/Repr_Learning/MaskGit/maskgit_jax2/models/mvtm/checkpoints\n"
     ]
    },
    {
     "data": {
      "text/plain": "'/home/bluesun/PycharmProjects/Repr_Learning/MaskGit/maskgit_jax2/models/mvtm/checkpoints/checkpoint_11'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flax.training import checkpoints\n",
    "import os, shutil\n",
    "\n",
    "path = os.path.abspath('./checkpoints')\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "print(path)\n",
    "checkpoints.save_checkpoint(path, target=state, step=state.step, keep=1, overwrite=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T03:59:37.953521Z",
     "start_time": "2024-03-21T03:59:37.772392Z"
    }
   },
   "id": "b6899f260ac1b470",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    }
   ],
   "source": [
    "re_state = checkpoints.restore_checkpoint(path, state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T04:00:32.354100Z",
     "start_time": "2024-03-21T04:00:32.200754Z"
    }
   },
   "id": "705ca94701749b3e",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "scripts.common.TrainState"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(re_state)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T04:01:16.458376Z",
     "start_time": "2024-03-21T04:01:16.455053Z"
    }
   },
   "id": "f37ca8589511c35a",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'conv': {'bias': (256,), 'kernel': (1, 1, 256, 256)},\n 'decoder': {'Attention_0': {'Conv_0': {'kernel': (1, 1, 256, 768)},\n   'Conv_1': {'kernel': (1, 1, 256, 256)},\n   'GroupNorm_0': {'bias': (256,), 'scale': (256,)}},\n  'ConvIn': {'bias': (256,), 'kernel': (3, 3, 256, 256)},\n  'ConvOut': {'kernel': (3, 3, 64, 3)},\n  'GroupNorm_0': {'bias': (64,), 'scale': (64,)},\n  'ResBlock_0': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n   'Conv_1': {'kernel': (1, 1, 256, 256)},\n   'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n   'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n  'ResBlock_1': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n   'Conv_1': {'kernel': (1, 1, 256, 256)},\n   'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n   'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n  'UpBlock_0': {'ResBlock_0': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n    'Conv_1': {'kernel': (1, 1, 256, 256)},\n    'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n    'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n   'ResBlock_1': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n    'Conv_1': {'kernel': (1, 1, 256, 256)},\n    'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n    'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n   'ResBlock_2': {'Conv_0': {'kernel': (3, 3, 256, 128)},\n    'Conv_1': {'kernel': (1, 1, 128, 128)},\n    'Conv_2': {'kernel': (1, 1, 256, 128)},\n    'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n    'GroupNorm_1': {'bias': (128,), 'scale': (128,)}},\n   'ResBlock_3': {'Conv_0': {'kernel': (3, 3, 128, 128)},\n    'Conv_1': {'kernel': (1, 1, 128, 128)},\n    'GroupNorm_0': {'bias': (128,), 'scale': (128,)},\n    'GroupNorm_1': {'bias': (128,), 'scale': (128,)}},\n   'ResBlock_4': {'Conv_0': {'kernel': (3, 3, 128, 64)},\n    'Conv_1': {'kernel': (1, 1, 64, 64)},\n    'Conv_2': {'kernel': (1, 1, 128, 64)},\n    'GroupNorm_0': {'bias': (128,), 'scale': (128,)},\n    'GroupNorm_1': {'bias': (64,), 'scale': (64,)}},\n   'ResBlock_5': {'Conv_0': {'kernel': (3, 3, 64, 64)},\n    'Conv_1': {'kernel': (1, 1, 64, 64)},\n    'GroupNorm_0': {'bias': (64,), 'scale': (64,)},\n    'GroupNorm_1': {'bias': (64,), 'scale': (64,)}},\n   'Upsample_0': {'Conv_0': {'kernel': (3, 3, 256, 256)}},\n   'Upsample_1': {'Conv_0': {'kernel': (3, 3, 128, 128)}}}},\n 'encoder': {'Attention_0': {'Conv_0': {'kernel': (1, 1, 256, 768)},\n   'Conv_1': {'kernel': (1, 1, 256, 256)},\n   'GroupNorm_0': {'bias': (256,), 'scale': (256,)}},\n  'ConvIn': {'kernel': (3, 3, 3, 64)},\n  'ConvOut': {'kernel': (3, 3, 256, 256)},\n  'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n  'ResBlock_0': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n   'Conv_1': {'kernel': (1, 1, 256, 256)},\n   'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n   'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n  'ResBlock_1': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n   'Conv_1': {'kernel': (1, 1, 256, 256)},\n   'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n   'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n  'UpBlock': {'Downsample_0': {'Conv_0': {'kernel': (3, 3, 64, 64)}},\n   'Downsample_1': {'Conv_0': {'kernel': (3, 3, 128, 128)}},\n   'ResBlock_0': {'Conv_0': {'kernel': (3, 3, 64, 64)},\n    'Conv_1': {'kernel': (1, 1, 64, 64)},\n    'GroupNorm_0': {'bias': (64,), 'scale': (64,)},\n    'GroupNorm_1': {'bias': (64,), 'scale': (64,)}},\n   'ResBlock_1': {'Conv_0': {'kernel': (3, 3, 64, 64)},\n    'Conv_1': {'kernel': (1, 1, 64, 64)},\n    'GroupNorm_0': {'bias': (64,), 'scale': (64,)},\n    'GroupNorm_1': {'bias': (64,), 'scale': (64,)}},\n   'ResBlock_2': {'Conv_0': {'kernel': (3, 3, 64, 128)},\n    'Conv_1': {'kernel': (1, 1, 128, 128)},\n    'Conv_2': {'kernel': (1, 1, 64, 128)},\n    'GroupNorm_0': {'bias': (64,), 'scale': (64,)},\n    'GroupNorm_1': {'bias': (128,), 'scale': (128,)}},\n   'ResBlock_3': {'Conv_0': {'kernel': (3, 3, 128, 128)},\n    'Conv_1': {'kernel': (1, 1, 128, 128)},\n    'GroupNorm_0': {'bias': (128,), 'scale': (128,)},\n    'GroupNorm_1': {'bias': (128,), 'scale': (128,)}},\n   'ResBlock_4': {'Conv_0': {'kernel': (3, 3, 128, 256)},\n    'Conv_1': {'kernel': (1, 1, 256, 256)},\n    'Conv_2': {'kernel': (1, 1, 128, 256)},\n    'GroupNorm_0': {'bias': (128,), 'scale': (128,)},\n    'GroupNorm_1': {'bias': (256,), 'scale': (256,)}},\n   'ResBlock_5': {'Conv_0': {'kernel': (3, 3, 256, 256)},\n    'Conv_1': {'kernel': (1, 1, 256, 256)},\n    'GroupNorm_0': {'bias': (256,), 'scale': (256,)},\n    'GroupNorm_1': {'bias': (256,), 'scale': (256,)}}}},\n 'post_conv': {'bias': (256,), 'kernel': (1, 1, 256, 256)},\n 'vq': {'codebook': (512, 256)}}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(jp.shape, re_state.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T04:01:41.170067Z",
     "start_time": "2024-03-21T04:01:41.163281Z"
    }
   },
   "id": "6541334d5ae90e5c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d4649eec7b99441a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
